{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN on larger portion of sky tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycv5080/miniconda3/envs/cs449/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchfusion.gan.applications import DCGANDiscriminator\n",
    "\n",
    "from data_loader import MarioDataset\n",
    "from models.custom import Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run with \"python main.py\"\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--nz\", type=int, default=32, help=\"size of the latent z vector\"\n",
    "    )\n",
    "    parser.add_argument(\"--ngf\", type=int, default=64)\n",
    "    parser.add_argument(\"--ndf\", type=int, default=64)\n",
    "    parser.add_argument(\"--batchSize\", type=int,\n",
    "                        default=32, help=\"input batch size\")\n",
    "    parser.add_argument(\n",
    "        \"--niter\", type=int, default=10000, help=\"number of epochs to train for\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lrD\",\n",
    "        type=float,\n",
    "        default=0.00005,\n",
    "        help=\"learning rate for Critic, default=0.00005\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lrG\",\n",
    "        type=float,\n",
    "        default=0.00005,\n",
    "        help=\"learning rate for Generator, default=0.00005\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--beta1\", type=float, default=0.5, help=\"beta1 for adam. default=0.5\"\n",
    "    )\n",
    "    parser.add_argument(\"--cuda\", action=\"store_true\", help=\"enables cuda\")\n",
    "    parser.add_argument(\"--ngpu\", type=int, default=1,\n",
    "                        help=\"number of GPUs to use\")\n",
    "    parser.add_argument(\n",
    "        \"--netG\", default=\"\", help=\"path to netG (to continue training)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--netD\", default=\"\", help=\"path to netD (to continue training)\"\n",
    "    )\n",
    "    parser.add_argument(\"--clamp_lower\", type=float, default=-0.01)\n",
    "    parser.add_argument(\"--clamp_upper\", type=float, default=0.01)\n",
    "    parser.add_argument(\n",
    "        \"--Diters\", type=int, default=5, help=\"number of D iters per each G iter\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--n_extra_layers\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Number of extra layers on gen and disc\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--experiment\", default=None, help=\"Where to store samples and models\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--adam\", action=\"store_true\", help=\"Whether to use adam (default is rmsprop)\"\n",
    "    )\n",
    "    parser.add_argument(\"--problem\", type=int,\n",
    "                        default=0, help=\"Level examples\")\n",
    "    opt = parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def tiles2image(tiles, z_dims):\n",
    "    '''\n",
    "    Plotting the image from numeric encodings at this stage is just using the \n",
    "    color map to visualize different color. \n",
    "    '''\n",
    "    return plt.get_cmap(\"rainbow\")(tiles / float(z_dims))\n",
    "\n",
    "\n",
    "def combine_images(generated_images):\n",
    "    '''\n",
    "    the generated_images is the output of tiles2image\n",
    "    '''\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[1:]\n",
    "    image = np.zeros(\n",
    "        (height * shape[0], width * shape[1], shape[2]), dtype=generated_images.dtype\n",
    "    )\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index / width)\n",
    "        j = index % width\n",
    "        image[\n",
    "            i * shape[0]: (i + 1) * shape[0], j * shape[1]: (j + 1) * shape[1]\n",
    "        ] = img\n",
    "    return image\n",
    "\n",
    "\n",
    "def count_sky_tiles(joined_frame):\n",
    "    print(\"Joined frame =\")\n",
    "    print(joined_frame)\n",
    "    level = np.argmax(joined_frame[:, :, 9:-9, 2:-2].data.cpu().numpy(), axis=1)\n",
    "    sky_region, upper_half = level[:,:10,:], level[:,:7,:]\n",
    "    print(\"sky region =\")\n",
    "    print(sky_region)\n",
    "    print(\"upper_half =\")\n",
    "    print(upper_half)\n",
    "    ground_tiles = np.logical_or(level == 0, level == 1)\n",
    "\n",
    "    num_enemies = np.sum(np.logical_and(level[:,:-1,:] == 5, ground_tiles[:,1:,:]),axis=1)\n",
    "    num_sky_enemies = np.sum(level == 5,axis=1) - num_enemies\n",
    "    num_sky_tiles = np.sum(np.logical_and(sky_region != 2, sky_region != 5))\n",
    "    num_sky_tiles_at_half = np.sum(np.logical_and(upper_half != 2, upper_half != 5))\n",
    "    num_ground_tiles = np.sum(level == 0)\n",
    "    num_pipes = np.sum(level == 6)\n",
    "\n",
    "    return (\n",
    "        (num_sky_tiles_at_half + num_sky_tiles)\n",
    "        - num_ground_tiles\n",
    "        + 10 * np.sum(np.logical_or(level == 5, level == 11, level == 12))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "    netG, netD, org_data, opt, nz, z_dims, map_size, num_batches, conditional_channels\n",
    "):\n",
    "    '''\n",
    "    netG: generator\n",
    "    netD: discrimminator\n",
    "    org_data: from MarioDataset(), size = (2488,13,32,32), where (2488,13,9:-9, 2:-2) is the onehot encoding and others are zeros\n",
    "    opt: whether using cuda\n",
    "    nz: 14 * 32 * 32,\n",
    "    z_dim: number of mapped symbols (tile types)\n",
    "    map_size: 32\n",
    "    batchsize: default 32\n",
    "\n",
    "    The condition of the DCGAN is the previous frame\n",
    "    '''\n",
    "    input = torch.FloatTensor(opt.batchSize, z_dims, map_size, map_size)\n",
    "    noise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\n",
    "    # fill the tensor with elements samples from the normal distribution\n",
    "    fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "    one = torch.FloatTensor([1])\n",
    "    mone = one * -1\n",
    "\n",
    "    if opt.cuda:\n",
    "        netD.cuda()\n",
    "        netG.cuda()\n",
    "        input = input.cuda()\n",
    "        one, mone = one.cuda(), mone.cuda()\n",
    "        noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "        org_data.cuda()\n",
    "\n",
    "    # setup optimizer\n",
    "    if opt.adam:\n",
    "        optimizerD = optim.Adam(\n",
    "            netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
    "        optimizerG = optim.Adam(\n",
    "            netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
    "        print(\"Using ADAM\")\n",
    "    else:\n",
    "        optimizerD = optim.RMSprop(netD.parameters(), lr=opt.lrD)\n",
    "        optimizerG = optim.RMSprop(netG.parameters(), lr=opt.lrG)\n",
    "\n",
    "    gen_iterations = 0\n",
    "    for epoch in range(opt.niter):\n",
    "\n",
    "        #! data_iter = iter(dataloader)\n",
    "        # random permuation of intergers: generate random interger without repeating\n",
    "        data_idx = torch.randperm(len(org_data))\n",
    "\n",
    "        i = 0\n",
    "        while i < num_batches:  # len(dataloader):\n",
    "            ############################\n",
    "            # (1) Update D network\n",
    "            ###########################\n",
    "            for p in netD.parameters():  # reset requires_grad\n",
    "                p.requires_grad = True  # they are set to False below in netG update\n",
    "\n",
    "            # train the discriminator Diters times\n",
    "            if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "                Diters = 100  # what is Diter for?\n",
    "            else:\n",
    "                Diters = opt.Diters\n",
    "            j = 0\n",
    "            while j < Diters and i < num_batches:  # len(dataloader):\n",
    "                j += 1\n",
    "\n",
    "                # clamp parameters to a cube\n",
    "                for p in netD.parameters():\n",
    "                    # the value < lb will be replaced by lb and > ub by ub\n",
    "                    # why do they add this?\n",
    "                    p.data.clamp_(opt.clamp_lower, opt.clamp_upper)\n",
    "\n",
    "                batch_data = org_data[\n",
    "                    data_idx[i * opt.batchSize: (i + 1) * opt.batchSize]\n",
    "                ]  # generate batch data from original dataset\n",
    "\n",
    "                i += 1\n",
    "                context_frame, out_frame = (batch_data[0], batch_data[1])\n",
    "\n",
    "                if False:\n",
    "                    # im = data.cpu().numpy()\n",
    "                    print(batch_data.shape)\n",
    "                    real_cpu = combine_images(\n",
    "                        tiles2image(np.argmax(batch_data, axis=1),\n",
    "                                    z_dims=z_dims)\n",
    "                    )\n",
    "                    print(real_cpu)\n",
    "                    plt.imsave(\n",
    "                        \"{0}/real_samples.png\".format(opt.experiment), real_cpu)\n",
    "                    exit()\n",
    "\n",
    "                netD.zero_grad()\n",
    "                # batch_size = num_samples #real_cpu.size(0)\n",
    "\n",
    "                if opt.cuda:\n",
    "                    context_frame.cuda(), out_frame.cuda()\n",
    "                joined_frame = torch.cat((context_frame, out_frame), dim=3)\n",
    "                true, false = count_sky_tiles(joined_frame)\n",
    "                # the size of every joined_frame (for a single level) is (13,32,32)\n",
    "                assert joined_frame[0].shape == (13, 32, 32)\n",
    "                true_joined_frame = joined_frame[true]\n",
    "                print(true_joined_frame)\n",
    "                print(true_joined_frame.size)\n",
    "                \n",
    "                input.resize_as_(joined_frame).copy_(\n",
    "                    joined_frame)\n",
    "                inputv = Variable(input)  # make input as variables wrt loss\n",
    "\n",
    "                # forward the batch sample through netD and get error: the corresponding label shoule be \"real\"\n",
    "                errD_real = netD(inputv).mean(0).view(1)\n",
    "                errD_real.backward(one)\n",
    "\n",
    "                # train with fake\n",
    "                noise.resize_(opt.batchSize, 1, 14, 14).normal_(0, 1)\n",
    "\n",
    "                ref_idx = torch.randperm(len(org_data))[: opt.batchSize]\n",
    "                # only take take out the first half of the frame\n",
    "                ref_frames = org_data[ref_idx].prev_frame\n",
    "                gen_input = torch.cat(\n",
    "                    (noise, ref_frames[:,\n",
    "                     conditional_channels, 9:-9, 2:]), dim=1  # conditional channel = [0,1,6,7]\n",
    "                )\n",
    "                # gen_input.size() = [opt.batchSize,5,14,14]\n",
    "                # gen_input = ref_frames[:, :, 9:-9, 2:]\n",
    "\n",
    "                # totally freeze netG\n",
    "                noisev = Variable(gen_input, volatile=True) # what is volatile=True?\n",
    "                # generated latent variables from netG, **size = (batchSize,?,32,32)\n",
    "                fake = Variable(netG(noisev).data)\n",
    "                stitched = torch.cat(\n",
    "                    (ref_frames, fake[:, :, :, 16:]), dim=3\n",
    "                )  # stitch the first half and the generated fake second have together\n",
    "                assert stitched[0].shape == (13, 32, 32)\n",
    "                inputv = stitched\n",
    "                errD_fake = netD(inputv).mean(0).view(\n",
    "                    1)  # tell netD this is the fake one.\n",
    "                # get gradient for the fake data. mone is to tell netD this is the fake model\n",
    "                errD_fake.backward(mone)\n",
    "                errD = errD_real - errD_fake  # To track error difference\n",
    "                optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "\n",
    "            # For each batch\n",
    "            for p in netD.parameters():\n",
    "                p.requires_grad = False  # Freeze netD, to avoid computation\n",
    "            netG.zero_grad()\n",
    "            # in case our last batch was the tail batch of the dataloader,\n",
    "            # make sure we feed a full batch of noise\n",
    "            noise.resize_(opt.batchSize, 1, 14, 14).normal_(0, 1)\n",
    "\n",
    "            ref_idx = torch.randperm(len(org_data))[: opt.batchSize]\n",
    "            ref_frames = org_data[ref_idx].prev_frame\n",
    "\n",
    "            gen_input = torch.cat(\n",
    "                (noise, ref_frames[:, conditional_channels, 9:-9, 2:]), dim=1\n",
    "            )\n",
    "            # gen_input = ref_frames[:, :, 9:-9, 2:]\n",
    "\n",
    "            g_input = Variable(gen_input)\n",
    "            fake = netG(g_input)\n",
    "            # fake[:, :, :, :16] = ref_frames\n",
    "            stitched = torch.cat((ref_frames, fake[:, :, :, 16:]), dim=3)\n",
    "            errG = netD(stitched).mean(0).view(1)\n",
    "            errG.backward(one)\n",
    "            optimizerG.step()\n",
    "            gen_iterations += 1\n",
    "            # 0430/2023\n",
    "            print(\n",
    "                \"[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    opt.niter,\n",
    "                    i,\n",
    "                    num_batches,\n",
    "                    gen_iterations,\n",
    "                    errD.data[0],\n",
    "                    errG.data[0],\n",
    "                    errD_real.data[0],\n",
    "                    errD_fake.data[0],\n",
    "\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # np.savetxt(\"Loss_D.csv\", np.asarray(errD.data[0]), delimiter = \",\")\n",
    "            # np.savetxt(\"Loss_G.csv\", np.asarray(errG.data[0]), delimiter = \",\")\n",
    "            # np.savetxt(\"Loss_D_real.csv\", np.asarray(errD_real.data[0]), delimiter = \",\")\n",
    "            # np.savetxt(\"Loss_D_fake.csv\", np.asarray(errD_fake.data[0]), delimiter = \",\")\n",
    "\n",
    "            # What is this part doing?\n",
    "            if gen_iterations % 10000 == 0:  # was 500\n",
    "                # iteration through 10000 batches\n",
    "                with torch.no_grad():\n",
    "                    fixed_noise.resize_(opt.batchSize, 1, 14, 14)\n",
    "                    ref_idx = torch.randperm(len(org_data))[: opt.batchSize]\n",
    "                    ref_frames = org_data[ref_idx].prev_frame\n",
    "                    gen_input = torch.cat(\n",
    "                        (fixed_noise,\n",
    "                         ref_frames[:, conditional_channels, 9:-9, 2:]),\n",
    "                        dim=1,\n",
    "                    )\n",
    "                    # gen_input = ref_frames[:, :, 9:-9, 2:]\n",
    "                    fake = netG(Variable(gen_input, volatile=True))\n",
    "                stitched = torch.cat((ref_frames, fake[:, :, :, 16:]), dim=3)\n",
    "                im = stitched.data.cpu().numpy()\n",
    "                im = im[:, :, 9:-9, 1:-2]  # why -1:2 not -2:2\n",
    "                # print('SHAPE fake',type(im), im.shape)\n",
    "                # print('SUM ',np.sum( im, axis = 1) )\n",
    "\n",
    "                im = combine_images(tiles2image(\n",
    "                    np.argmax(im, axis=1), z_dims=13))  # why argmax?\n",
    "                plt.imsave(\n",
    "                    \"{0}/mario_fake_samples_1_{1}.png\".format(\n",
    "                        opt.experiment, gen_iterations\n",
    "                    ),\n",
    "                    im,\n",
    "                )\n",
    "                torch.save(\n",
    "                    netG.state_dict(),\n",
    "                    \"{0}/netG_epoch_condition_1_{1}_{2}_{3}.pth\".format(\n",
    "                        opt.experiment, gen_iterations, opt.problem, opt.nz\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        # do checkpointing\n",
    "        # torch.save(netG.state_dict(), '{0}/netG_epoch_{1}.pth'.format(opt.experiment, epoch))\n",
    "        # torch.save(netD.state_dict(), '{0}/netD_epoch_{1}.pth'.format(opt.experiment, epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--nz NZ] [--ngf NGF] [--ndf NDF]\n",
      "                             [--batchSize BATCHSIZE] [--niter NITER]\n",
      "                             [--lrD LRD] [--lrG LRG] [--beta1 BETA1] [--cuda]\n",
      "                             [--ngpu NGPU] [--netG NETG] [--netD NETD]\n",
      "                             [--clamp_lower CLAMP_LOWER]\n",
      "                             [--clamp_upper CLAMP_UPPER] [--Diters DITERS]\n",
      "                             [--n_extra_layers N_EXTRA_LAYERS]\n",
      "                             [--experiment EXPERIMENT] [--adam]\n",
      "                             [--problem PROBLEM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9061 --control=9059 --hb=9058 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ffe31309-24a7-4f79-88b3-9d67cd5ae38d\" --shell=9060 --transport=\"tcp\" --iopub=9062 --f=/home/ycv5080/.local/share/jupyter/runtime/kernel-v2-28239i7SkU2bMqfBh.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = parse_arguments()\n",
    "\n",
    "if opt.experiment is None:\n",
    "    opt.experiment = \"samples\"\n",
    "os.system(\"mkdir {0}\".format(opt.experiment))\n",
    "\n",
    "opt.manualSeed = random.randint(1, 10000)  # fix seed\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "map_size = 32\n",
    "data = MarioDataset()\n",
    "# channels on which generator is conditioned on\n",
    "conditional_channels = [0,1,2,5,6,7]\n",
    "\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)\n",
    "\n",
    "# n_extra_layers = int(opt.n_extra_layers)\n",
    "\n",
    "# netG = dcgan.DCGAN_G(map_size, nz, z_dims, ngf, ngpu, n_extra_layers)\n",
    "netG = Generator(\n",
    "    latent_size=(len(conditional_channels) + 1, 14, 14), out_size=(13, 32, 32)\n",
    ")\n",
    "# what does the latent size means? the dimension of the inputs\n",
    "print(netG)\n",
    "# netG.apply(weights_init)\n",
    "# if opt.netG != \"\":  # load checkpoint if needed\n",
    "#     netG.load_state_dict(torch.load(opt.netG))\n",
    "\n",
    "netD = DCGANDiscriminator(input_size=(13, 32, 32), apply_sigmoid=False)\n",
    "print(netD)\n",
    "# netD.apply(weights_init)\n",
    "# if opt.netD != \"\":\n",
    "# netD.load_state_dict(torch.load(opt.netD))\n",
    "num_batches = len(data) / opt.batchSize\n",
    "train(\n",
    "    netG=netG,\n",
    "    netD=netD,\n",
    "    org_data=data,\n",
    "    opt=opt,\n",
    "    nz=14 * 32 * 32,\n",
    "    z_dims=14,\n",
    "    map_size=32,\n",
    "    num_batches=num_batches,\n",
    "    conditional_channels=conditional_channels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--nz NZ] [--ngf NGF] [--ndf NDF]\n",
      "                             [--batchSize BATCHSIZE] [--niter NITER]\n",
      "                             [--lrD LRD] [--lrG LRG] [--beta1 BETA1] [--cuda]\n",
      "                             [--ngpu NGPU] [--netG NETG] [--netD NETD]\n",
      "                             [--clamp_lower CLAMP_LOWER]\n",
      "                             [--clamp_upper CLAMP_UPPER] [--Diters DITERS]\n",
      "                             [--n_extra_layers N_EXTRA_LAYERS]\n",
      "                             [--experiment EXPERIMENT] [--adam]\n",
      "                             [--problem PROBLEM]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9061 --control=9059 --hb=9058 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ffe31309-24a7-4f79-88b3-9d67cd5ae38d\" --shell=9060 --transport=\"tcp\" --iopub=9062 --f=/home/ycv5080/.local/share/jupyter/runtime/kernel-v2-28239i7SkU2bMqfBh.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycv5080/miniconda3/envs/cs449/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs449",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
