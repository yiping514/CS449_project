{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID with GAN generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchfusion.gan.applications import DCGANDiscriminator\n",
    "\n",
    "from data_loader import MarioDataset\n",
    "from models.custom import Generator\n",
    "\n",
    "import csv\n",
    "\n",
    "from image_gen.asset_map import get_asset_map\n",
    "from image_gen.fixer import PipeFixer\n",
    "from image_gen.image_gen import GameImageGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from get_level import GetLevel as getLevel\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the matrices\n",
    "def preprocess_matrices(matrices):\n",
    "    # Normalize values to the range [0, 255]\n",
    "    normalized_matrices = (matrices - np.min(matrices)) / (np.max(matrices) - np.min(matrices))\n",
    "    normalized_matrices = normalized_matrices * 255\n",
    "    return normalized_matrices.astype(np.uint8)\n",
    "\n",
    "# Function to compute mean and covariance of features\n",
    "def compute_statistics(matrices):\n",
    "    # Flatten matrices into vectors\n",
    "    flattened_matrices = matrices.reshape((matrices.shape[0], -1))\n",
    "    # Compute mean and covariance\n",
    "    mean = np.mean(flattened_matrices, axis=0)\n",
    "    covariance = np.cov(flattened_matrices, rowvar=False)\n",
    "\n",
    "    return mean, covariance\n",
    "\n",
    "# Function to compute FrÃ©chet distance\n",
    "def compute_frechet_distance(real_mean, real_cov, generated_mean, generated_cov):\n",
    "    epsilon = 1e-6  # Small constant to avoid numerical instability\n",
    "    sqrt_cov_product = sqrtm(real_cov.dot(generated_cov))\n",
    "    fid_score = np.linalg.norm(real_mean - generated_mean) + np.trace(real_cov + generated_cov - 2 * sqrt_cov_product)\n",
    "\n",
    "    return fid_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches for Real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 6]\n",
      "  [2 2 2 ... 2 2 8]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 6 7]\n",
      "  [2 2 2 ... 2 8 9]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 0 2]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "org_data = MarioDataset()\n",
    "ref_idx = torch.randperm(len(org_data))\n",
    "prev_frame, curr_frame = (org_data[:].prev_frame, org_data[:].curr_frame)\n",
    "complete_frame = torch.cat((prev_frame,curr_frame),dim=3)\n",
    "complete_frame = torch.argmax(complete_frame, dim = 1)\n",
    "#complete_frame = torch.tensor(complete_frame,dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess real data\n",
    "complete_frame_np = complete_frame.detach().numpy()\n",
    "real_matrices = preprocess_matrices(complete_frame_np)\n",
    "# Compute statistics for real matrices\n",
    "real_mean, real_cov = compute_statistics(real_matrices)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches for generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 6]\n",
      "  [2 2 2 ... 2 2 8]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 6 7]\n",
      "  [2 2 2 ... 2 8 9]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  ...\n",
      "  [2 2 2 ... 2 2 2]\n",
      "  [2 2 2 ... 2 0 2]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycv5080/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset \u001b[39m=\u001b[39m MarioDataset()\n\u001b[1;32m      3\u001b[0m netG \u001b[39m=\u001b[39m Generator(\n\u001b[1;32m      4\u001b[0m         latent_size\u001b[39m=\u001b[39m(\u001b[39mlen\u001b[39m(conditional_channels) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m14\u001b[39m, \u001b[39m14\u001b[39m), out_size\u001b[39m=\u001b[39m(\u001b[39m13\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m)\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0m netG\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m./trained_models/netG_epoch_300000_0_32.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m     \u001b[39m# 300000\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mario_map \u001b[39m=\u001b[39m get_asset_map(game\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmario\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/cs449/lib/python3.9/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "\n",
    "conditional_channels = conditional_channels = [0,1,6,7]\n",
    "dataset = MarioDataset()\n",
    "netG = Generator(\n",
    "        latent_size=(len(conditional_channels) + 1, 14, 14), out_size=(13, 32, 32)\n",
    "    )\n",
    "netG.load_state_dict(torch.load(\"./trained_models/netG_epoch_300000_0_32.pth\"))\n",
    "    # 300000\n",
    "mario_map = get_asset_map(game=\"mario\")\n",
    "gen = GameImageGenerator(asset_map=mario_map)\n",
    "prev_frame, curr_frame = dataset[[120]]\n",
    "fixer = PipeFixer()\n",
    "\n",
    "level_gen = getLevel(netG, gen, fixer, prev_frame, curr_frame, conditional_channels)\n",
    "var = 1\n",
    "#noise = np.rand((1, 1, 14, 14)).normal_(0, var)\n",
    "noise = np.random.normal(0,var,size=(14,14))\n",
    "level = level_gen.generate_frames(noise, var=var, frame_count=1) # generated matrix without padded\n",
    "padded = torch.zeros(32,32)\n",
    "padded[9:-9,2:-2] = torch.from_numpy(level)\n",
    "level = padded\n",
    "level_finalize = torch.zeros(1,32,32)\n",
    "level_finalize[0,:,:] = level\n",
    "level = level_finalize\n",
    "\n",
    "# this is just for visualization\n",
    "level_gen.gen.save_gen_level(img_name=\"test_fuc_gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess generated data\n",
    "generated_frame_np = level.detach().numpy()\n",
    "generated_matrices = preprocess_matrices(generated_frame_np)\n",
    "# Compute statistics for real matrices\n",
    "gen_mean, gen_cov = compute_statistics(generated_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Compute FrÃ©chet distance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fid_score \u001b[39m=\u001b[39m compute_frechet_distance(real_mean, real_cov, gen_mean, gen_cov)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFID score:\u001b[39m\u001b[39m\"\u001b[39m, fid_score)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'real_mean' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute FrÃ©chet distance\n",
    "fid_score = compute_frechet_distance(real_mean, real_cov, gen_mean, gen_cov)\n",
    "print(\"FID score:\", fid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs449_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
