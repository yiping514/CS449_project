{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID with GAN generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ycv5080/miniconda3/envs/cs449_project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchfusion.gan.applications import DCGANDiscriminator\n",
    "\n",
    "from data_loader import MarioDataset\n",
    "from models.custom import Generator\n",
    "\n",
    "import csv\n",
    "\n",
    "from image_gen.asset_map import get_asset_map\n",
    "from image_gen.fixer import PipeFixer\n",
    "from image_gen.image_gen import GameImageGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from get_level import GetLevel as getLevel\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the matrices\n",
    "def preprocess_matrices(matrices):\n",
    "    # Normalize values to the range [0, 255]\n",
    "    normalized_matrices = (matrices - np.min(matrices)) / (np.max(matrices) - np.min(matrices))\n",
    "    normalized_matrices = normalized_matrices * 255\n",
    "    return normalized_matrices.astype(np.uint8)\n",
    "\n",
    "# Function to compute mean and covariance of features\n",
    "def compute_statistics(matrices):\n",
    "    # Flatten matrices into vectors\n",
    "    flattened_matrices = matrices.reshape((matrices.shape[0], -1))\n",
    "    # Compute mean and covariance\n",
    "    mean = np.mean(flattened_matrices, axis=0)\n",
    "    covariance = np.cov(flattened_matrices, rowvar=False)\n",
    "\n",
    "    return mean, covariance\n",
    "\n",
    "# Function to compute Fréchet distance\n",
    "def compute_frechet_distance(real_mean, real_cov, generated_mean, generated_cov):\n",
    "    epsilon = 1e-6  # Small constant to avoid numerical instability\n",
    "    sqrt_cov_product = sqrtm(real_cov.dot(generated_cov))\n",
    "    fid_score = np.linalg.norm(real_mean - generated_mean) + np.trace(real_cov + generated_cov - 2 * sqrt_cov_product)\n",
    "\n",
    "    return fid_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches for Real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data = MarioDataset()\n",
    "ref_idx = torch.randperm(len(org_data))\n",
    "prev_frame, curr_frame = (org_data[:].prev_frame, org_data[:].curr_frame)\n",
    "complete_frame = torch.cat((prev_frame,curr_frame),dim=3)\n",
    "#convert one-hot encoding back to 2D matrices\n",
    "complete_frame = torch.argmax(complete_frame, dim = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess real data\n",
    "complete_frame_np = complete_frame.detach().numpy()\n",
    "real_matrices = preprocess_matrices(complete_frame_np)\n",
    "# Compute statistics for real matrices\n",
    "real_mean, real_cov = compute_statistics(real_matrices)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches for generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_channels = [0,1,6,7]\n",
    "def Gen_sample(conditional_channels,ini_data=120):\n",
    "    dataset = MarioDataset()\n",
    "    netG = Generator(\n",
    "            latent_size=(len(conditional_channels) + 1, 14, 14), out_size=(13, 32, 32)\n",
    "        )\n",
    "    netG.load_state_dict(torch.load(\"./trained_models/netG_epoch_300000_0_32.pth\"))\n",
    "        # 300000\n",
    "    mario_map = get_asset_map(game=\"mario\")\n",
    "    gen = GameImageGenerator(asset_map=mario_map)\n",
    "    prev_frame, curr_frame = dataset[[ini_data]]\n",
    "    fixer = PipeFixer()\n",
    "\n",
    "    level_gen = getLevel(netG, gen, fixer, prev_frame, curr_frame, conditional_channels)\n",
    "    var = 1\n",
    "    #noise = np.rand((1, 1, 14, 14)).normal_(0, var)\n",
    "    noise = np.random.normal(0,var,size=(14,14))\n",
    "    level = level_gen.generate_frames(noise, var=var, frame_count=1) # generated matrix without padded\n",
    "    # convert to onehot encoding\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "    # onehot = np.eye(13, dtype=\"uint8\")[level]  # create a one hot mapping for the features\n",
    "    # onehot = np.rollaxis(onehot, 2, 0)  # (num_samples, chann.=13, h=14, w=28)\n",
    "    # padded = np.full((1, onehot.shape[0], 32, 32), 0.0)\n",
    "    # padded[:, :, 9:-9, 2:-2] = onehot\n",
    "    # padded = torch.from_numpy(padded)\n",
    "    # return padded\n",
    "\n",
    "    padded = torch.zeros(32,32)\n",
    "    padded[9:-9,2:-2] = torch.from_numpy(level)\n",
    "    level = padded\n",
    "\n",
    "    return level\n",
    "    # this is just for visualization\n",
    "    #level_gen.gen.save_gen_level(img_name=\"test_fuc_gen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of generated samples \n",
    "n_gen = 100\n",
    "\n",
    "# generate samples and stack together\n",
    "#level_gen = torch.zeros(n_gen,13,32,32)\n",
    "level_gen = torch.zeros(n_gen,32,32)\n",
    "for i in range(n_gen):\n",
    "    level = Gen_sample(conditional_channels,ini_data=120)\n",
    "    level_gen[i,:,:] = level\n",
    "    #level_gen[i,:,:,:] = level\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess generated data\n",
    "generated_frame_np = level_gen.detach().numpy()\n",
    "generated_matrices = preprocess_matrices(generated_frame_np)\n",
    "# Compute statistics for real matrices\n",
    "gen_mean, gen_cov = compute_statistics(generated_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID score: (151142.54590961675-0.0003873447056625816j)\n"
     ]
    }
   ],
   "source": [
    "# Compute Fréchet distance\n",
    "fid_score = compute_frechet_distance(real_mean, real_cov, gen_mean, gen_cov)\n",
    "print(\"FID score:\", fid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs449_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
